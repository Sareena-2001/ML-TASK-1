# -*- coding: utf-8 -*-
"""MACHINE LEARNING TASK 1:CREDIT SCORING MODEL

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GkQJ-ueU7m-EaGmQwxw-WrNhbbTeKgjP
"""

#LIBRARIES

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB

from sklearn.metrics import classification_report, confusion_matrix

#WE'LL LOAD THE DATASET NOW


# Load dataset
creditscoring_dataset = pd.read_csv('/content/sample_data/Credit Score Classification Dataset.csv')

creditscoring_dataset.head(7)

creditscoring_dataset.tail(9)

creditscoring_dataset.shape

creditscoring_dataset.columns

#FIGURING OUT THE MISSING VALUES IN THE DATASET

print("The number of missing values in the dataset is:\n", creditscoring_dataset.isnull().sum())

#THE MISSING VALUES ARE TO BE REPLACED WITH AVERAGE/MEAN OF THAT RESPECTIVE COLUMN
#IT IS APPLICABLE FOR COLUMNS BASED ON NUMERICAL DATA


creditscoring_dataset.fillna(creditscoring_dataset.mean(numeric_only=True), inplace=True)

#BOX PLOT FOR DATA VISUALIZATION

plt.figure(figsize=(14,8))

plt.subplot(1, 2, 1)
sns.boxplot(data=creditscoring_dataset,palette='gray')
plt.xticks(rotation=85)
plt.title('Box Plot')

#VIOLIN PLOT FOR DATA VISUALIZATION

plt.figure(figsize=(12, 6))



plt.subplot(1, 2, 2)
sns.violinplot(data=creditscoring_dataset,palette='Reds')
plt.xticks(rotation=90)
plt.title('Violin Plot')

plt.tight_layout()
plt.show()

#WE DO HAVE COLUMNS WITH CATEGORICAL VALUES IN THE DATASET, WE'LL APPLY LABEL ENCODING ON THEM




# LABEL ENCODING IS TO BE APPLIED ON CATEGORICAL COLUMNS
lab_enc = {}
cat_columns = ['Gender', 'Education', 'Marital Status', 'Home Ownership']

# LABEL ENCODING IS APPLIED TO THE DATASET'S CATEGORICAL COLUMNS
for colu in cat_columns:
    lenco = LabelEncoder()
    creditscoring_dataset[colu] = lenco.fit_transform(creditscoring_dataset[colu])
    lab_enc[colu] = lenco

# Encode target variable, i.e., Credit Score
tar_enc = LabelEncoder()
creditscoring_dataset['Credit Score'] = tar_enc.fit_transform(creditscoring_dataset['Credit Score'])

# WE NOW WILL VERIFY ENCODING
print(creditscoring_dataset.head())

# THE DATA IS THEN SPLIT INTO FEATURES AND TARGET VARIABLES

X = creditscoring_dataset.drop('Credit Score', axis=1)
y = creditscoring_dataset['Credit Score']

# 80-20 train,test ratio
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# FEATURE STANDARDIZATION

sca = StandardScaler()
X_train = sca.fit_transform(X_train)
X_test = sca.transform(X_test)

# THE FOLLOWING CLASSIFIERS ARE USED

Classif = {
    'Logistic Regression': LogisticRegression(),
    'Random Forest': RandomForestClassifier(),
    'SVM': SVC(),
    'Naive Bayes': GaussianNB()
}

# Train models, make predictions, and plot confusion matrices
for nameofmodel, model in Classif.items():
    # Fit the model
    model.fit(X_train, y_train)

    # Make predictions
    y_predicted = model.predict(X_test)

    # Print classification report
    print(f"{nameofmodel} Classification Report for the Classifier:\n", classification_report(y_test, y_predicted))

    # Compute confusion matrix
    con_mat = confusion_matrix(y_test, y_predicted)

    # Plot confusion matrix
    plt.figure(figsize=(7, 5))
    sns.heatmap(con_mat, annot=True, fmt='d', cmap='YlOrBr', cbar=False,
                xticklabels=tar_enc.classes_, yticklabels=tar_enc.classes_)
    plt.title(f'{nameofmodel} Confusion Matrix for the Classifier')
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.show()

# WE HAVE TO HANDLE UNSEEN LABELS IN DATA TOO

def encodingour_data(dat, enc):
    encod_dat = dat.copy()
    for column in enc:
        if dat[column].dtype == 'object':
            le = enc[column]
            uni_lab = le.classes_.tolist() #for unique labels
            # Add any new labels to the encoder
            for lab in dat[column].unique():
                if lab not in uni_lab:
                    le.classes_ = np.append(le.classes_, lab)
            encod_dat[column] = le.transform(dat[column])
    return encod_dat

# NOW PREDICTIONS ARE TO BE MADE
newdata = pd.DataFrame({
    'Age': [51],
    'Gender': ['Male'],
    'Income': [135000],
    'Education': ["Bachelor's"],
    'Marital Status': ['Married'],
    'Number of Children': [0],
    'Home Ownership': ['Owned']
})

# NEW DATA IS TO BE ENCODED TOO
encode_newdata = encodingour_data(newdata, lab_enc)
encode_newdata = sca.transform(encode_newdata)

#PREDICTIONS FOR NEW DATA
for name, model in Classif.items():
    prediction = model.predict(encode_newdata)
    # Decode the prediction to original label
    original_label = tar_enc.inverse_transform(prediction)
    print(f"{name} Prediction for the provided data is : {original_label[0]}")